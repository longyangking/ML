{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Association rule learning\n",
    "+ Apriori Algorithm\n",
    "+ FP-growth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Association rule learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Apriori Algorithm\n",
    "__Apriori__ is an algorithm for frequent item set mining and association rule learning over transactional databases. It proceeds by identifying the frequent individual items in the database and extending them to larger and larger item sets as long as those item sets appear sufficiently often in the database. The frequent item sets determined by Apriori can be used to determine association rules which highlight general trends in the database: this has applications in domains such as market basket analysis.\n",
    "\n",
    "Apriori is designed to operate on databases containing transactions(for example, collections of items bought by customers, or details of a website frequentation). Each transaction is seen as a set of items(an itemset). Given a threshold __C__, the Apriori algorithm identifies the item sets which are subsets of at least __C__ transactions in the database.\n",
    "\n",
    "Apriori uses a \"bottom up\" approach, where frequent subsets are extended on item at a time(a step known as _candidate generation_), and groups of candidates are tested against the data. The algorithm terminates when no further successful extensions are found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process\n",
    "The pseudo code for the algorithm is given below for a transaction database __$T$__, and a support threshold of $\\epsilon$. Usual set theoretic notation is employed, though note that __$T$__ is a multiset. $C_k$ is the candidate set for level __$k$__. At each step, the algorithm is assumed to generate the candidate sets from the large item sets of the preceding level, heeding the downward closure lemma. __$count[c]$__ accesses a field of the data structur\n",
    "e that represents candidate set __$c$__, which is initially assumed to be zero.\n",
    "\n",
    "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/8eed75c18217fe2f9b15f266c40b369ce038164d) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitations\n",
    "Apriori, while historically significant, suffers from a number of inefficiencies or trade-offs, which have spawne other algorithms. Candidate generation generates large numbers of subsets(the algorithm attempts to load up the candidate set with as many as possible before each scan). Bottom-up subset exploration(essentially a breadth-first traversal of the subset lattice) finds any maximal subset S only after all $2^{|S|}-1$ of its proper subsets.\n",
    "\n",
    "Later algorithms such as Max-Miner try to identify the maximal frequent item sets without enumerating their subsets, and perform \"jumps\" in the search space rather than a purely bottom-up approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##  Frequent Pattern Mining / The FP-growth algorithm\n",
    "In Data Mining, the task of finding frequent pattern in large database is very important and has been studied in large scale in the past few years. For details, click [here](https://en.wikibooks.org/wiki/Data_Mining_Algorithms_In_R/Frequent_Pattern_Mining/The_FP-Growth_Algorithm).\n",
    "\n",
    "The FP-Growth algorithm is an efficient and scalable method for mining the complete set of frequent patterns by pattern fragment growth, using an extended prefix-tree structure for storing compressed and crucial information about frequent patterns named frequent-pattern tree (FP-tree)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### FP-Tree Structure\n",
    "The FP-Growth Algorithm is an alternative way to find frequent itemsets without using candidate generations, thus improving performance. For so much it uses a divide-and-conquer strategy. The core of this method is the usage of a special data structure named frquent-pattern tree (FP-tree), which retains the itemset association information.\n",
    "\n",
    "In simple words, this algorithm works as follows: first it compresses the input database creating an FP-tree instance to represent frequent items. After this first step it divides the compressed database into a set of conditional databases, each one associated with one frequent pattern. Finally, each such database is mined separately. Using this strategy, the FP-Growth reduces the search costs looking for short patterns recursively and then concatenating them in the long frequent patterns, offering good selectivity.\n",
    "\n",
    "In large databases, itâ€™s not possible to hold the FP-tree in the main memory. A strategy to cope with this problem is to firstly partition the database into a set of smaller databases (called projected databases), and then construct an FP-tree from each of these smaller databases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FP-Tree structure\n",
    "The frequent-pattern tree (FP-tree) is a compact structure that stores quantitative information about frequent patterns in a database.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
